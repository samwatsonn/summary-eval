{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2a13697d70df4208"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:16:09.025627Z",
     "start_time": "2024-03-15T16:16:08.688362Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\theaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\theaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\theaw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from summary_eval.data import summary_df, prompts_df\n",
    "from summary_eval.testing import cross_validate\n",
    "from summary_eval.settings import TRAIN_SIZE\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "join_df = summary_df.merge(prompts_df, on=\"prompt_id\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:16:09.041167Z",
     "start_time": "2024-03-15T16:16:09.029178Z"
    }
   },
   "id": "448b72af3edbc6e3",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92867128279cb212"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "BASIC_FEATURES = [\n",
    "    \"num_words\",\n",
    "    \"num_sentences\",\n",
    "    \"words_per_sentence\",\n",
    "]\n",
    "\n",
    "LT_FEATURES = [\n",
    "    'count_TYPOS_norm',\n",
    "    'count_REDUNDANCY_norm',\n",
    "    'count_PUNCTUATION_norm',\n",
    "    'count_TYPOGRAPHY_norm',\n",
    "    'count_STYLE_norm',\n",
    "    'count_GRAMMAR_norm',\n",
    "    'count_CASING_norm',\n",
    "    'count_CONFUSED_WORDS_norm'\n",
    "]\n",
    "\n",
    "QUOTE_FEATURES = [\n",
    "    \"quoteCount\",\n",
    "    \"avgQuoteLength\",\n",
    "    \"propTextInQuotes\",\n",
    "    \"propWordsInQuotes\",\n",
    "    \"propQuotationsInPrompt\"\n",
    "]\n",
    "\n",
    "TEXTBLOB_FEATURES = [\n",
    "    \"propSentencesStartedWithConjunctions\",\n",
    "    \"propConjunctions\",\n",
    "    \"propPronouns\",\n",
    "    \"propAdverbs\",\n",
    "    \"propVerbs\",\n",
    "    \"propNouns\",\n",
    "    \"propAdjectives\",\n",
    "    \"propAdjectivesRepeated2pTextNormalised\",\n",
    "    \"propAdjectivesRepeated2p\",\n",
    "    \"subjectivity\",\n",
    "    \"polarity\"\n",
    "]\n",
    "\n",
    "TEXTSTAT_FEATURES = [\n",
    "    \"syllables_per_word\"\n",
    "]\n",
    "\n",
    "FEATURES = BASIC_FEATURES + LT_FEATURES + QUOTE_FEATURES + TEXTBLOB_FEATURES + TEXTSTAT_FEATURES\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:16:09.056686Z",
     "start_time": "2024-03-15T16:16:09.044429Z"
    }
   },
   "id": "dc797d4dcbd70d70",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NLTK - Basic Features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dee285530073fdf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nltk"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:16:09.072370Z",
     "start_time": "2024-03-15T16:16:09.060685Z"
    }
   },
   "id": "53c4a8ea09cf8e01",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "summary_df[\"num_words\"] = summary_df[\"text\"].apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "summary_df[\"num_sentences\"] = summary_df[\"text\"].apply(lambda x: len(nltk.sent_tokenize(x)))\n",
    "summary_df[\"words_per_sentence\"] = summary_df[\"num_words\"] / summary_df[\"num_sentences\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:16:13.213836Z",
     "start_time": "2024-03-15T16:16:09.075861Z"
    }
   },
   "id": "ca711fd54c8451d4",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Language Tool\n",
    "Spelling and grammar based features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f927085fa9b74a18"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import language_tool_python\n",
    "tool = language_tool_python.LanguageTool('en-US')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:16:16.429703Z",
     "start_time": "2024-03-15T16:16:13.216123Z"
    }
   },
   "id": "e4f191eea7bc01c2",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7165/7165 [07:46<00:00, 15.35it/s]\n"
     ]
    }
   ],
   "source": [
    "mistake_categories = [\n",
    "    'TYPOS',\n",
    "    'REDUNDANCY',\n",
    "    'PUNCTUATION',\n",
    "    'TYPOGRAPHY',\n",
    "    'STYLE',\n",
    "    'GRAMMAR',\n",
    "    'CASING',\n",
    "    'CONFUSED_WORDS'\n",
    "]\n",
    "\n",
    "def pre_process_whitespace(text: str) -> str:\n",
    "    # Replace all whitespace with a single space\n",
    "    text = ' '.join(text.split())\n",
    "    # Remove leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def count_dict_field(matches: dict, field: str) -> dict:\n",
    "    issue_counts = {}\n",
    "    for match in matches:\n",
    "        if getattr(match, field) in issue_counts:\n",
    "            issue_counts[getattr(match, field)] += 1\n",
    "        else:\n",
    "            issue_counts[getattr(match, field)] = 1\n",
    "    return issue_counts\n",
    "\n",
    "def mistake_category_counts(text):\n",
    "    matches = tool.check(pre_process_whitespace(text))\n",
    "    category_count = count_dict_field(matches, 'category')\n",
    "    return [category_count.get(c, 0) for c in mistake_categories]\n",
    "\n",
    "def grammar_mistakes(df):\n",
    "    new_df = df.copy()\n",
    "    temp = list(zip(*new_df['text'].progress_map(mistake_category_counts)))\n",
    "    for i, c in enumerate(mistake_categories): \n",
    "        new_df[f\"count_{c}\"] = temp[i]\n",
    "    return new_df\n",
    "\n",
    "summary_df = grammar_mistakes(summary_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:24:03.273874Z",
     "start_time": "2024-03-15T16:16:16.432875Z"
    }
   },
   "id": "c21414b49742f560",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "summary_df[\"text_len\"] = summary_df[\"text\"].apply(len)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:31:37.605785Z",
     "start_time": "2024-03-15T16:31:37.582423Z"
    }
   },
   "id": "2de67b4a9862cb56",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for c in mistake_categories:\n",
    "    summary_df[f\"count_{c}_norm\"] = summary_df[f\"count_{c}\"] / summary_df[\"text_len\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:31:39.291381Z",
     "start_time": "2024-03-15T16:31:39.268941Z"
    }
   },
   "id": "9ddf7a2d2f6b79ab",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Quotation Features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f95610447cccf76"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:24:03.289750Z",
     "start_time": "2024-03-15T16:24:03.276878Z"
    }
   },
   "id": "a5b603ef93214c05",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def split_quotations(text: str) -> (str, List[str]):\n",
    "    quotations = re.findall('\"([^\"]*)\"', text)\n",
    "    no_quote_text = text\n",
    "    for quotation in quotations:\n",
    "        no_quote_text = no_quote_text.replace(f'\"{quotation}\"', \"\")\n",
    "    return no_quote_text, quotations"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:24:03.304815Z",
     "start_time": "2024-03-15T16:24:03.291812Z"
    }
   },
   "id": "8a3177ed48794663",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7165/7165 [00:00<00:00, 7927.61it/s] \n"
     ]
    }
   ],
   "source": [
    "def count_quotations(text: str) -> int:\n",
    "    return len(re.findall('\"([^\"]*)\"', text))\n",
    "\n",
    "def avg_quote_length(text: str) -> float:\n",
    "    no_quote_text, quotations = split_quotations(text)\n",
    "    if len(quotations) == 0:\n",
    "        return 0\n",
    "    return sum(len(q) for q in quotations) / len(quotations)\n",
    "\n",
    "def prop_text_in_quotes(text: str) -> float:\n",
    "    no_quote_text, quotations = split_quotations(text)\n",
    "    return (len(text)-len(no_quote_text)) / len(text)\n",
    "\n",
    "def prop_words_in_quotes(text: str, num_words: int) -> float:\n",
    "    no_quote_text, quotations = split_quotations(text)\n",
    "    return (num_words-len(nltk.word_tokenize(no_quote_text))) / num_words\n",
    "\n",
    "def get_alpha(s: str) -> str:\n",
    "    return ''.join([c for c in s if c.isalpha() or c.isspace()])\n",
    "\n",
    "def process_str(s: str) -> str:\n",
    "    return pre_process_whitespace(get_alpha(s).lower())\n",
    "\n",
    "def prop_quotations_in_prompt(prompt: str, summary: str):\n",
    "    summary_quotations = set(re.findall('\"([^\"]*)\"', summary))\n",
    "    \n",
    "    if len(summary_quotations) == 0:\n",
    "        return None\n",
    "    \n",
    "    # process prompt\n",
    "    prompt_processed = process_str(prompt)\n",
    "    summary_quotations = set([process_str(q) for q in summary_quotations])\n",
    "    \n",
    "    # for q in summary_quotations:\n",
    "    #     if q not in prompt_processed:\n",
    "    #         print(q, prompt_processed)\n",
    "    #         break\n",
    "    \n",
    "    return len([q for q in summary_quotations if q in prompt_processed]) / len(summary_quotations)\n",
    "\n",
    "summary_df[\"quoteCount\"] = summary_df[\"text\"].apply(count_quotations)\n",
    "summary_df[\"avgQuoteLength\"] = summary_df[\"text\"].apply(avg_quote_length)\n",
    "summary_df[\"propTextInQuotes\"] = summary_df[\"text\"].apply(prop_text_in_quotes)\n",
    "summary_df[\"propWordsInQuotes\"] = summary_df.apply(lambda row: prop_words_in_quotes(row[\"text\"], row[\"num_words\"]), axis=1)\n",
    "summary_df[\"propQuotationsInPrompt\"] = join_df.progress_apply(lambda row: prop_quotations_in_prompt(row[\"prompt_text\"], row[\"text\"]), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:24:07.794536Z",
     "start_time": "2024-03-15T16:24:03.307820Z"
    }
   },
   "id": "b91230260e988b9b",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TextBlob - POS Features"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a39cade7e18d7c5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from typing import Optional"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:24:07.872753Z",
     "start_time": "2024-03-15T16:24:07.797664Z"
    }
   },
   "id": "cecda6667a8198d2",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7165/7165 [00:00<00:00, 12311.30it/s]\n",
      "100%|██████████| 7165/7165 [00:33<00:00, 210.74it/s]\n",
      "100%|██████████| 7165/7165 [00:34<00:00, 209.55it/s]\n",
      "100%|██████████| 7165/7165 [00:34<00:00, 209.54it/s]\n",
      "100%|██████████| 7165/7165 [00:34<00:00, 206.60it/s]\n",
      "100%|██████████| 7165/7165 [00:34<00:00, 208.64it/s]\n",
      "100%|██████████| 7165/7165 [00:34<00:00, 206.86it/s]\n",
      "100%|██████████| 7165/7165 [00:33<00:00, 211.19it/s]\n",
      "100%|██████████| 7165/7165 [00:34<00:00, 210.28it/s]\n",
      "100%|██████████| 7165/7165 [00:02<00:00, 2484.42it/s]\n",
      "100%|██████████| 7165/7165 [00:02<00:00, 2557.15it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_polarity(text: str) -> float:\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "def get_subjectivity(text: str) -> float:\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.subjectivity\n",
    "\n",
    "def textblob_pos_filter(text: str, pos_tag: str) -> List[str]:\n",
    "    blob = TextBlob(text)\n",
    "    return [word for word, pos in blob.tags if pos.startswith(pos_tag)]\n",
    "\n",
    "def count_duplicates(words: List[str]) -> dict:\n",
    "    word_counts = {}\n",
    "    for word in words:\n",
    "        if word in word_counts:\n",
    "            word_counts[word] += 1\n",
    "        else:\n",
    "            word_counts[word] = 1\n",
    "    return word_counts\n",
    "\n",
    "def prop_adjectives_repeated(text: str) -> Optional[float]:\n",
    "    adjectives = textblob_pos_filter(text, \"JJ\")\n",
    "    if len(adjectives) == 0:\n",
    "        return None\n",
    "    return len([word for word, count in count_duplicates(adjectives).items() if count >= 2]) / len(adjectives)\n",
    "\n",
    "def prop_adjectives_repeated_text_normalised(text: str) -> Optional[float]:\n",
    "    adjectives = textblob_pos_filter(text, \"JJ\")\n",
    "    if len(adjectives) == 0:\n",
    "        return None\n",
    "    return len([word for word, count in count_duplicates(adjectives).items() if count >= 2]) / len(text)\n",
    "\n",
    "def prop_pos_words(text: str, num_words: int, pos: str) -> float:\n",
    "    words = textblob_pos_filter(text, pos)\n",
    "    return len(words) / num_words\n",
    "\n",
    "def prop_sentences_started_with_conjunctions(text: str) -> float:\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    conjunctions = [\"and\", \"but\", \"or\", \"yet\", \"so\", \"for\", \"nor\"]\n",
    "    count = 0\n",
    "    for sentence in sentences:\n",
    "        if sentence.split()[0].lower() in conjunctions:\n",
    "            count += 1\n",
    "    return count / len(sentences)\n",
    "\n",
    "summary_df[\"propSentencesStartedWithConjunctions\"] = summary_df[\"text\"].progress_apply(prop_sentences_started_with_conjunctions)\n",
    "summary_df[\"propConjunctions\"] = summary_df.progress_apply(lambda row: prop_pos_words(row[\"text\"], row[\"num_words\"], \"CC\"), axis=1)\n",
    "summary_df[\"propPronouns\"] = summary_df.progress_apply(lambda row: prop_pos_words(row[\"text\"], row[\"num_words\"], \"PRP\"), axis=1)\n",
    "summary_df[\"propAdverbs\"] = summary_df.progress_apply(lambda row: prop_pos_words(row[\"text\"], row[\"num_words\"], \"RB\"), axis=1)\n",
    "summary_df[\"propVerbs\"] = summary_df.progress_apply(lambda row: prop_pos_words(row[\"text\"], row[\"num_words\"], \"VB\"), axis=1)\n",
    "summary_df[\"propNouns\"] = summary_df.progress_apply(lambda row: prop_pos_words(row[\"text\"], row[\"num_words\"], \"NN\"), axis=1)\n",
    "summary_df[\"propAdjectives\"] = summary_df.progress_apply(lambda row: prop_pos_words(row[\"text\"], row[\"num_words\"], \"JJ\"), axis=1)\n",
    "summary_df[\"propAdjectivesRepeated2pTextNormalised\"] = summary_df[\"text\"].progress_apply(prop_adjectives_repeated_text_normalised)\n",
    "summary_df[\"propAdjectivesRepeated2p\"] = summary_df[\"text\"].progress_apply(prop_adjectives_repeated)\n",
    "summary_df[\"subjectivity\"] = summary_df[\"text\"].progress_apply(get_subjectivity)\n",
    "summary_df[\"polarity\"] = summary_df[\"text\"].progress_apply(get_polarity)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:28:48.258906Z",
     "start_time": "2024-03-15T16:24:07.875056Z"
    }
   },
   "id": "8f2a36861a3ded13",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TextStat"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dd556670aef8c33"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import textstat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:28:48.443497Z",
     "start_time": "2024-03-15T16:28:48.261198Z"
    }
   },
   "id": "b9b3f5fa83f9b562",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "summary_df[\"num_syllables\"] = summary_df[\"text\"].apply(textstat.syllable_count)\n",
    "summary_df[\"syllables_per_word\"] = summary_df[\"num_syllables\"] / summary_df[\"num_words\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:28:49.295753Z",
     "start_time": "2024-03-15T16:28:48.446549Z"
    }
   },
   "id": "a0d97284dff3936",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c1af2832dd18f33"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:32:35.004049Z",
     "start_time": "2024-03-15T16:32:34.991919Z"
    }
   },
   "id": "de9cdd4796416a84",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "X = summary_df[FEATURES]\n",
    "y = summary_df[[\"content\", \"wording\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:31:43.210838Z",
     "start_time": "2024-03-15T16:31:43.200915Z"
    }
   },
   "id": "d2a65fdcf06a4a61",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(5732, 1433, 5732, 1433)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=TRAIN_SIZE, random_state=42)\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:31:45.776102Z",
     "start_time": "2024-03-15T16:31:45.760235Z"
    }
   },
   "id": "55738403fc3bb91c",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 16:32:45,104 - INFO - Using 10x10 cross validation\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0afea328c5af4755a2695f4ab33679c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Metric        rmse                                 mae            \\\nTarget     content   wording mean_columnwise   content   wording   \nmean       0.47739  0.654725        0.566057  0.358751  0.500674   \nstdev     0.018187  0.026518        0.022352  0.010665  0.017992   \nn_trials       100       100               2       100       100   \n\nMetric                          r2                            \nTarget   mean_columnwise   content   wording mean_columnwise  \nmean            0.429713  0.789046  0.603164        0.696105  \nstdev           0.014329  0.017464  0.031755         0.02461  \nn_trials               2       100       100               2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th>Metric</th>\n      <th colspan=\"3\" halign=\"left\">rmse</th>\n      <th colspan=\"3\" halign=\"left\">mae</th>\n      <th colspan=\"3\" halign=\"left\">r2</th>\n    </tr>\n    <tr>\n      <th>Target</th>\n      <th>content</th>\n      <th>wording</th>\n      <th>mean_columnwise</th>\n      <th>content</th>\n      <th>wording</th>\n      <th>mean_columnwise</th>\n      <th>content</th>\n      <th>wording</th>\n      <th>mean_columnwise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>mean</th>\n      <td>0.47739</td>\n      <td>0.654725</td>\n      <td>0.566057</td>\n      <td>0.358751</td>\n      <td>0.500674</td>\n      <td>0.429713</td>\n      <td>0.789046</td>\n      <td>0.603164</td>\n      <td>0.696105</td>\n    </tr>\n    <tr>\n      <th>stdev</th>\n      <td>0.018187</td>\n      <td>0.026518</td>\n      <td>0.022352</td>\n      <td>0.010665</td>\n      <td>0.017992</td>\n      <td>0.014329</td>\n      <td>0.017464</td>\n      <td>0.031755</td>\n      <td>0.02461</td>\n    </tr>\n    <tr>\n      <th>n_trials</th>\n      <td>100</td>\n      <td>100</td>\n      <td>2</td>\n      <td>100</td>\n      <td>100</td>\n      <td>2</td>\n      <td>100</td>\n      <td>100</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiOutputRegressor(HistGradientBoostingRegressor(random_state=0))\n",
    "results_df = cross_validate(model, X_train, y_train)\n",
    "results_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T16:34:03.927046Z",
     "start_time": "2024-03-15T16:32:45.101849Z"
    }
   },
   "id": "53b19d82d944957b",
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Save feature_df to csv to avoid re-running the above code"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85d81bdd4e909af2"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "aa6455fc4d38f28b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "summary_df.to_csv(\"../data/feature_df.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-15T17:25:16.503133Z",
     "start_time": "2024-03-15T17:25:16.227512Z"
    }
   },
   "id": "972680e5f22c9110",
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
