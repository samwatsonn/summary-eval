{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 00:21:42,704 - INFO - Read 7165 summaries from D:\\summary-eval\\data\\summaries_train.csv\n",
      "2024-05-12 00:21:42,707 - INFO - Read 4 prompts from D:\\summary-eval\\data\\prompts_train.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import torch\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "\n",
    "path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "ppath = os.path.abspath(os.path.join(path, os.pardir))\n",
    "sys.path.append(ppath)\n",
    "\n",
    "from summary_eval.data import summary_df, prompts_df\n",
    "from summary_eval.settings import TRAIN_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>the article by UShistory. Org  \"Egypt social s...</td>\n",
       "      <td>0.846025</td>\n",
       "      <td>-0.344397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>In the upper class  There was the royal famile...</td>\n",
       "      <td>-0.456956</td>\n",
       "      <td>-0.042516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>In the Egyptian government system only the nob...</td>\n",
       "      <td>0.376374</td>\n",
       "      <td>0.463619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6189</th>\n",
       "      <td>Aristotle describes many elements of an ideal ...</td>\n",
       "      <td>1.690740</td>\n",
       "      <td>1.461055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>They would use chemicals to get rid of mold an...</td>\n",
       "      <td>0.050689</td>\n",
       "      <td>0.260165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>The social classes were involved due to how th...</td>\n",
       "      <td>-0.970237</td>\n",
       "      <td>-0.417058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>Jonas had told them how the meat that was take...</td>\n",
       "      <td>-1.547163</td>\n",
       "      <td>-1.461245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>In The Jungle, when meat was spoiled it could ...</td>\n",
       "      <td>1.038163</td>\n",
       "      <td>0.928848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>One element is that a tragedy should be arrang...</td>\n",
       "      <td>0.531368</td>\n",
       "      <td>0.583991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>They would mix the spoiled meat with the good ...</td>\n",
       "      <td>-0.595403</td>\n",
       "      <td>-0.242357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5732 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   content   wording\n",
       "2441  the article by UShistory. Org  \"Egypt social s...  0.846025 -0.344397\n",
       "3901  In the upper class  There was the royal famile... -0.456956 -0.042516\n",
       "4267  In the Egyptian government system only the nob...  0.376374  0.463619\n",
       "6189  Aristotle describes many elements of an ideal ...  1.690740  1.461055\n",
       "4119  They would use chemicals to get rid of mold an...  0.050689  0.260165\n",
       "...                                                 ...       ...       ...\n",
       "3772  The social classes were involved due to how th... -0.970237 -0.417058\n",
       "5191  Jonas had told them how the meat that was take... -1.547163 -1.461245\n",
       "5226  In The Jungle, when meat was spoiled it could ...  1.038163  0.928848\n",
       "5390  One element is that a tragedy should be arrang...  0.531368  0.583991\n",
       "860   They would mix the spoiled meat with the good ... -0.595403 -0.242357\n",
       "\n",
       "[5732 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(summary_df, train_size=TRAIN_SIZE, random_state=42)\n",
    "train_df.drop([\"student_id\", \"prompt_id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_chars(df, **kwargs):\n",
    "    \"\"\"\n",
    "    actions:\n",
    "    - 'insert' random chars into the text\n",
    "    - 'substitute' chars randomly with other chars\n",
    "    - 'swap' chars with another char in the text\n",
    "    - 'delete' chars randomly\n",
    "    https://nlpaug.readthedocs.io/en/latest/augmenter/char/random.html\n",
    "    \"\"\"\n",
    "    text = df['text'].tolist()\n",
    "    \n",
    "    aug = nac.random.RandomCharAug(kwargs)\n",
    "    return np.array(aug.augment(text))\n",
    "\n",
    "def ocr_aug(df, **kwargs):\n",
    "    \"\"\"\n",
    "    adds typical errors usually seen from ocr\n",
    "    https://nlpaug.readthedocs.io/en/latest/augmenter/char/ocr.html\n",
    "    \"\"\"\n",
    "    text = df['text'].tolist()\n",
    "\n",
    "    aug = nac.ocr.OcrAug(kwargs)\n",
    "    return np.array(aug.augment(text))\n",
    "\n",
    "def spelling_aug(df, **kwargs):\n",
    "    \"\"\"\n",
    "    adds spelling mistakes\n",
    "    https://nlpaug.readthedocs.io/en/latest/augmenter/word/spelling.html\n",
    "    \"\"\"\n",
    "    text = df['text'].tolist()\n",
    "\n",
    "    aug = naw.spelling.SpellingAug(kwargs)\n",
    "    return np.array(aug.augment(text))\n",
    "\n",
    "def random_words(df, **kwargs):\n",
    "    \"\"\"\n",
    "    actions:\n",
    "    - 'swap' word with another word (randomly) in the text\n",
    "    - 'delete' words randomly\n",
    "    https://nlpaug.readthedocs.io/en/latest/augmenter/word/random.html\n",
    "    \"\"\"\n",
    "    text = df['text'].tolist()\n",
    "\n",
    "    aug = naw.random.RandomWordAug(kwargs)\n",
    "    return np.array(aug.augment(text))\n",
    "\n",
    "def synonym_replacement(df, **kwargs):\n",
    "    \"\"\"\n",
    "    replace words with their synonyms\n",
    "    either use wordnet or ppdb\n",
    "    https://nlpaug.readthedocs.io/en/latest/augmenter/word/synonym.html\n",
    "    \"\"\"\n",
    "    text = df['text'].tolist()\n",
    "\n",
    "    aug = naw.SynonymAug()\n",
    "    return np.array(aug.augment(text))\n",
    "\n",
    "def back_translate(df):\n",
    "    text = df['text'].tolist()\n",
    "\n",
    "    aug = naw.back_translation.BackTranslationAug(from_model_name=\"Helsinki-NLP/opus-mt-en-de\",\n",
    "                                                  to_model_name=\"Helsinki-NLP/opus-mt-de-en\")\n",
    "    return np.array(aug.augment())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Daniel/.cache\\torch\\hub\\huggingface_pytorch-transformers_main\n",
      "d:\\summary-eval\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Using cache found in C:\\Users\\Daniel/.cache\\torch\\hub\\huggingface_pytorch-transformers_main\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-cased')\n",
    "masked_lm_model = torch.hub.load('huggingface/pytorch-transformers', 'modelForMaskedLM', 'bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_random_mask(text):\n",
    "    words = text.split()\n",
    "    mask_idx = random.randint(0, len(words))\n",
    "    new_words = words[:mask_idx] + [\"[MASK]\"] + words[mask_idx:]\n",
    "\n",
    "    return \" \".join(new_words)\n",
    "\n",
    "def substitute_random_mask(text):\n",
    "    words = text.split()\n",
    "    mask_idx = random.randint(0, len(words))\n",
    "    words[mask_idx] = \"[MASK]\"\n",
    "\n",
    "    return \" \".join(words)\n",
    "\n",
    "def bert(text):\n",
    "    tokens = tokenizer(text, padding=True)\n",
    "    mask_index = [i for i, token_id in enumerate(tokens[\"input_ids\"]) if token_id == tokenizer.mask_token_id]\n",
    "    \n",
    "    segments_tensors = torch.tensor([tokens[\"token_type_ids\"]])\n",
    "    tokens_tensor = torch.tensor([tokens[\"input_ids\"]])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = masked_lm_model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "    \n",
    "    pred_token = torch.argmax(predictions[0][0], dim=1)\n",
    "    tokens[\"input_ids\"][mask_index[0]] = pred_token[mask_index[0]]\n",
    "    \n",
    "    return tokenizer.decode(tokens[\"input_ids\"], skip_special_tokens=True)\n",
    "\n",
    "def bert_insert_random(df):\n",
    "    summaries = map(insert_random_mask, df['text'].tolist())\n",
    "    return numpy.array([bert(s) for s in summaries])\n",
    "\n",
    "def bert_substitute_random(df):\n",
    "    summaries = map(substitute_random_mask, df['text'].tolist())\n",
    "    return numpy.array([bert(s) for s in summaries])\n",
    "\n",
    "# can also test DistilBERT & RoBERTA equivalents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\" #set here or in .env\n",
    "ANTHROPIC_API_KEY = \"\" #set here or in .env\n",
    "openAiClient = OpenAI(api_key=OPENAI_API_KEY)\n",
    "anthropicClient = Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "\n",
    "def single_turn_openai(text):\n",
    "    return openAiClient.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Please rephrase the following sentence: {text}\"}\n",
    "        ]\n",
    "    ).choices[0].message.content\n",
    "\n",
    "def multi_turn_openai(text):\n",
    "    return openAiClient.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that rephrase text and make sentence smooth\"},\n",
    "            {\"role\": \"user\", \"content\": \"I will give you a sample, please rephrase it, then give me 6 rephrased answers\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Sure, please provide the sentence you would like me to rephrase.\"},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ]\n",
    "    ).choices[0].message.content\n",
    "\n",
    "def single_turn_anthropic(text):\n",
    "    return anthropicClient.messages.create(\n",
    "        model=\"claude-3-opus-20240229\",\n",
    "        max_tokens=1000,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": f\"Please rephrase the following sentence: {text}\"}\n",
    "        ]\n",
    "    ).choices[0].message.content\n",
    "\n",
    "def multi_turn_anthropic(text):\n",
    "    return anthropicClient.messages.create(\n",
    "        model=\"claude-3-opus-20240229\",\n",
    "        max_tokens=1000,\n",
    "        system=\"You are a helpful assistant that rephrase text and make sentence smooth\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"I will give you a sample, please rephrase it, then give me 6 rephrased answers\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Sure, please provide the sentence you would like me to rephrase.\"},\n",
    "            {\"role\": \"user\", \"content\": text},\n",
    "        ]\n",
    "    ).choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
