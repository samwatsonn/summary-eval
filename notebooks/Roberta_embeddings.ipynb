{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sys.path: ['c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\notebooks', 'C:\\\\Apps\\\\Anaconda3\\\\python311.zip', 'C:\\\\Apps\\\\Anaconda3\\\\DLLs', 'C:\\\\Apps\\\\Anaconda3\\\\Lib', 'C:\\\\Apps\\\\Anaconda3', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv', '', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:/Users/jp3g20/Desktop/data mining/summary-eval']\n",
      "Updated sys.path: ['c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\notebooks', 'C:\\\\Apps\\\\Anaconda3\\\\python311.zip', 'C:\\\\Apps\\\\Anaconda3\\\\DLLs', 'C:\\\\Apps\\\\Anaconda3\\\\Lib', 'C:\\\\Apps\\\\Anaconda3', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv', '', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import string\n",
    "print('Original sys.path:', sys.path)\n",
    "\n",
    "# Append a new directory to sys.path\n",
    "sys.path.append('C:/Users/jp3g20/Desktop/data mining/summary-eval')\n",
    "\n",
    "# Print the updated sys.path\n",
    "print('Updated sys.path:', sys.path)\n",
    "from summary_eval.data import summary_df, prompts_df\n",
    "from summary_eval.settings import TRAIN_SIZE\n",
    "from summary_eval.testing import cross_validate\n",
    "\n",
    "merged_df = pd.merge(summary_df, prompts_df, on='prompt_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu118\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jp3g20\\Desktop\\data mining\\summary-eval\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "# Load pre-trained RoBERTa model and tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "roberta_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Function to calculate average embedding of non-stopwords using RoBERTa\n",
    "def calculate_average_roberta_embedding(text):\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=True)\n",
    "\n",
    "    # Get RoBERTa outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = roberta_model(**inputs)\n",
    "    \n",
    "    # Extract hidden states from RoBERTa outputs\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "    \n",
    "    # Average pooling over all tokens (excluding padding tokens)\n",
    "    non_pad_mask = inputs[\"attention_mask\"].unsqueeze(-1).expand(hidden_states.size())\n",
    "    non_pad_hidden_states = hidden_states * non_pad_mask\n",
    "    sum_hidden_states = torch.sum(non_pad_hidden_states, 1)\n",
    "    sum_mask = non_pad_mask.sum(1)\n",
    "    mean_pooled = sum_hidden_states / sum_mask\n",
    "    \n",
    "    # Convert tensor to numpy array\n",
    "    avg_embedding = mean_pooled.squeeze().numpy()\n",
    "    \n",
    "    return avg_embedding\n",
    "\n",
    "# Apply function to 'text', 'prompt_text', and 'prompt_question' columns\n",
    "merged_df['text_embeddings_roberta'] = merged_df['text'].apply(calculate_average_roberta_embedding)\n",
    "merged_df['prompt_embeddings_roberta'] = merged_df['prompt_text'].apply(calculate_average_roberta_embedding)\n",
    "merged_df['prompt_question_embeddings_roberta'] = merged_df['prompt_question'].apply(calculate_average_roberta_embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('temp_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_folds = 5 \n",
    "\n",
    "k_folds = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "X_text_embeddings = np.vstack(merged_df['text_embeddings_roberta'].values)\n",
    "X_prompt_embeddings = np.vstack(merged_df['prompt_embeddings_roberta'].values)\n",
    "X_prompt_question_embeddings = np.vstack(merged_df['prompt_question_embeddings_roberta'].values)\n",
    "\n",
    "\n",
    "X_embeddings = np.hstack((X_text_embeddings, X_prompt_embeddings, X_prompt_question_embeddings))\n",
    "y = merged_df[['content', 'wording']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_embeddings, y, test_size=0.2, random_state=42)\n",
    "model = MultiOutputRegressor(HistGradientBoostingRegressor(random_state=0))\n",
    "\n",
    "for train_i, test_i in k_folds.split(X_train):\n",
    "    fold_train_X, fold_test_X = X_train[train_i], X_train[test_i]\n",
    "    fold_train_y, fold_test_y = y_train.to_numpy()[train_i], y_train.to_numpy()[test_i]\n",
    "    model.fit(fold_train_X, fold_train_y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.40668559051956643\n",
      "Mean Squared Error (MSE): 0.29108633720122284\n",
      "R-squared (R^2) score: 0.7226411408708024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared (R^2) score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Columnwise Root Mean Squared Error (MCRMSE): 0.5321691199462231\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mcrmse(y_true, y_pred):\n",
    "    rmse_per_column = np.sqrt(np.mean((y_true - y_pred)**2, axis=0))\n",
    "    mcrmse_value = np.mean(rmse_per_column)\n",
    "    return mcrmse_value\n",
    "\n",
    "mcrmse_score = mcrmse(y_test, y_pred)\n",
    "print(\"Mean Columnwise Root Mean Squared Error (MCRMSE):\", mcrmse_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv('feature_df.csv')\n",
    "merged_df_2 = pd.merge(merged_df, features_df, on=['student_id', 'prompt_id', 'text'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv('feature_df.csv')\n",
    "selected_features = features_df.drop(columns=['student_id', 'prompt_id', 'text', 'content', 'wording'])\n",
    "\n",
    "selected_features_array = selected_features.values\n",
    "\n",
    "X_combined = np.hstack((X_embeddings, selected_features_array))\n",
    "joe_features_df = pd.read_csv('joe_features.csv')\n",
    "\n",
    "selected_joe_features = joe_features_df[['mean word length', 'stopwords_count', 'repeated_words_prompt_text', 'repeated_words_prompt_question', 'fleschReadingEase']]\n",
    "\n",
    "selected_joe_features_array = selected_joe_features.values\n",
    "\n",
    "X_combined_with_joe_features = np.hstack((X_combined, selected_joe_features_array))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined_with_joe_features, y, test_size=0.2, random_state=42)\n",
    "model = MultiOutputRegressor(HistGradientBoostingRegressor(random_state=0))\n",
    "\n",
    "for train_i, test_i in k_folds.split(X_train):\n",
    "    fold_train_X, fold_test_X = X_train[train_i], X_train[test_i]\n",
    "    fold_train_y, fold_test_y = y_train.to_numpy()[train_i], y_train.to_numpy()[test_i]\n",
    "    model.fit(fold_train_X, fold_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 16:16:30,313 - INFO - Using 5x5 cross validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Columnwise Root Mean Squared Error (MCRMSE): 0.5046546465529266\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c792f9edb784e489f7859b3488d487a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"3\" halign=\"left\">rmse</th>\n",
       "      <th colspan=\"3\" halign=\"left\">mae</th>\n",
       "      <th colspan=\"3\" halign=\"left\">r2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>mean_columnwise</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>mean_columnwise</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>mean_columnwise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.428959</td>\n",
       "      <td>0.579758</td>\n",
       "      <td>0.504358</td>\n",
       "      <td>0.324097</td>\n",
       "      <td>0.443322</td>\n",
       "      <td>0.383709</td>\n",
       "      <td>0.830154</td>\n",
       "      <td>0.689906</td>\n",
       "      <td>0.76003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stdev</th>\n",
       "      <td>0.011931</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.011918</td>\n",
       "      <td>0.00771</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.008188</td>\n",
       "      <td>0.010128</td>\n",
       "      <td>0.011257</td>\n",
       "      <td>0.010693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_trials</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric        rmse                                 mae            \\\n",
       "Target     content   wording mean_columnwise   content   wording   \n",
       "mean      0.428959  0.579758        0.504358  0.324097  0.443322   \n",
       "stdev     0.011931  0.011905        0.011918   0.00771  0.008667   \n",
       "n_trials        25        25               2        25        25   \n",
       "\n",
       "Metric                          r2                            \n",
       "Target   mean_columnwise   content   wording mean_columnwise  \n",
       "mean            0.383709  0.830154  0.689906         0.76003  \n",
       "stdev           0.008188  0.010128  0.011257        0.010693  \n",
       "n_trials               2        25        25               2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mcrmse_score = mcrmse(y_test, y_pred)\n",
    "print(\"Mean Columnwise Root Mean Squared Error (MCRMSE):\", mcrmse_score)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "cross_validate(model, X_train, y_train, 5, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
