{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sys.path: ['c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\notebooks', 'C:\\\\Apps\\\\Anaconda3\\\\python311.zip', 'C:\\\\Apps\\\\Anaconda3\\\\DLLs', 'C:\\\\Apps\\\\Anaconda3\\\\Lib', 'C:\\\\Apps\\\\Anaconda3', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv', '', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:/Users/jp3g20/Desktop/summary_eval/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval']\n",
      "Updated sys.path: ['c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\notebooks', 'C:\\\\Apps\\\\Anaconda3\\\\python311.zip', 'C:\\\\Apps\\\\Anaconda3\\\\DLLs', 'C:\\\\Apps\\\\Anaconda3\\\\Lib', 'C:\\\\Apps\\\\Anaconda3', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv', '', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:/Users/jp3g20/Desktop/summary_eval/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import string\n",
    "print('Original sys.path:', sys.path)\n",
    "\n",
    "# Append a new directory to sys.path\n",
    "sys.path.append('C:/Users/jp3g20/Desktop/data mining/summary-eval')\n",
    "\n",
    "# Print the updated sys.path\n",
    "print('Updated sys.path:', sys.path)\n",
    "from summary_eval.data import summary_df, prompts_df\n",
    "from summary_eval.settings import TRAIN_SIZE\n",
    "from summary_eval.testing import cross_validate\n",
    "\n",
    "merged_df = pd.merge(summary_df, prompts_df, on='prompt_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu118\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jp3g20\\Desktop\\data mining\\summary-eval\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Function to calculate average embedding of non-stopwords using BERT\n",
    "def calculate_average_bert_embedding(text):\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=True)\n",
    "\n",
    "    # Get BERT outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    \n",
    "    # Extract hidden states from BERT outputs\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "    \n",
    "    # Average pooling over all tokens (excluding padding tokens)\n",
    "    non_pad_mask = inputs[\"attention_mask\"].unsqueeze(-1).expand(hidden_states.size())\n",
    "    non_pad_hidden_states = hidden_states * non_pad_mask\n",
    "    sum_hidden_states = torch.sum(non_pad_hidden_states, 1)\n",
    "    sum_mask = non_pad_mask.sum(1)\n",
    "    mean_pooled = sum_hidden_states / sum_mask\n",
    "    \n",
    "    # Convert tensor to numpy array\n",
    "    avg_embedding = mean_pooled.squeeze().numpy()\n",
    "    \n",
    "    return avg_embedding\n",
    "\n",
    "# Apply function to 'text', 'prompt_text', and 'prompt_question' columns\n",
    "merged_df['text_embeddings'] = merged_df['text'].apply(calculate_average_bert_embedding)\n",
    "merged_df['prompt_embeddings'] = merged_df['prompt_text'].apply(calculate_average_bert_embedding)\n",
    "merged_df['prompt_question_embeddings'] = merged_df['prompt_question'].apply(calculate_average_bert_embedding)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('temp_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_folds = 10 \n",
    "\n",
    "k_folds = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "X_text_embeddings = np.vstack(merged_df['text_embeddings'].values)\n",
    "X_prompt_embeddings = np.vstack(merged_df['prompt_embeddings'].values)\n",
    "X_prompt_question_embeddings = np.vstack(merged_df['prompt_question_embeddings'].values)\n",
    "\n",
    "\n",
    "X_embeddings = np.hstack((X_text_embeddings, X_prompt_embeddings, X_prompt_question_embeddings))\n",
    "y = merged_df[['content', 'wording']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_embeddings, y, test_size=0.2, random_state=42)\n",
    "model = MultiOutputRegressor(HistGradientBoostingRegressor(random_state=0))\n",
    "\n",
    "for train_i, test_i in k_folds.split(X_train):\n",
    "    fold_train_X, fold_test_X = X_train[train_i], X_train[test_i]\n",
    "    fold_train_y, fold_test_y = y_train.to_numpy()[train_i], y_train.to_numpy()[test_i]\n",
    "    model.fit(fold_train_X, fold_train_y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.43415684788616127\n",
      "Mean Squared Error (MSE): 0.3164194877895337\n",
      "R-squared (R^2) score: 0.6991313738653087\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared (R^2) score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Columnwise Root Mean Squared Error (MCRMSE): 0.5574291357675863\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mcrmse(y_true, y_pred):\n",
    "    rmse_per_column = np.sqrt(np.mean((y_true - y_pred)**2, axis=0))\n",
    "    mcrmse_value = np.mean(rmse_per_column)\n",
    "    return mcrmse_value\n",
    "\n",
    "mcrmse_score = mcrmse(y_test, y_pred)\n",
    "print(\"Mean Columnwise Root Mean Squared Error (MCRMSE):\", mcrmse_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using MLP regressor on embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 16:49:32,022 - INFO - Using 5x5 cross validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70fc21947d544eeadae564fce832725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     fold_train_y, fold_test_y \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mto_numpy()[train_i], y_train\u001b[38;5;241m.\u001b[39mto_numpy()[test_i]\n\u001b[0;32m      9\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(fold_train_X, fold_train_y)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users/jp3g20/Desktop/data mining/summary-eval\\summary_eval\\testing.py:90\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(model, X_train, y_train, n_folds, n_runs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcross_validate\u001b[39m(model, X_train, y_train, n_folds: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m N_FOLDS, n_runs: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m N_RUNS):\n\u001b[0;32m     89\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CrossValidator(model, X_train, y_train)\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_runs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users/jp3g20/Desktop/data mining/summary-eval\\summary_eval\\testing.py:47\u001b[0m, in \u001b[0;36mCrossValidator.cross_validate\u001b[1;34m(self, n_folds, n_runs)\u001b[0m\n\u001b[0;32m     45\u001b[0m k_folds \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39mn_folds, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mseeds[run_i])\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_i, test_i \u001b[38;5;129;01min\u001b[39;00m k_folds\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train):\n\u001b[1;32m---> 47\u001b[0m     fold_train_X, fold_test_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[train_i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train\u001b[38;5;241m.\u001b[39miloc[test_i]\n\u001b[0;32m     48\u001b[0m     fold_train_y, fold_test_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train\u001b[38;5;241m.\u001b[39miloc[train_i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train\u001b[38;5;241m.\u001b[39miloc[test_i]\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(fold_train_X, fold_train_y)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "y = merged_df[['content', 'wording']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_text_embeddings, y, test_size=0.2, random_state=42)\n",
    "model = MLPRegressor(random_state=0,hidden_layer_sizes=[384,120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 16:50:59,950 - INFO - Using 5x5 cross validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d54047b189b4834978972e1d72727c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"3\" halign=\"left\">rmse</th>\n",
       "      <th colspan=\"3\" halign=\"left\">mae</th>\n",
       "      <th colspan=\"3\" halign=\"left\">r2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>mean_columnwise</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>mean_columnwise</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>mean_columnwise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.505169</td>\n",
       "      <td>0.667834</td>\n",
       "      <td>0.586502</td>\n",
       "      <td>0.393945</td>\n",
       "      <td>0.521099</td>\n",
       "      <td>0.457522</td>\n",
       "      <td>0.764228</td>\n",
       "      <td>0.58835</td>\n",
       "      <td>0.676289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stdev</th>\n",
       "      <td>0.014642</td>\n",
       "      <td>0.013138</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.012041</td>\n",
       "      <td>0.010104</td>\n",
       "      <td>0.011072</td>\n",
       "      <td>0.017718</td>\n",
       "      <td>0.019163</td>\n",
       "      <td>0.018441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_trials</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric        rmse                                 mae            \\\n",
       "Target     content   wording mean_columnwise   content   wording   \n",
       "mean      0.505169  0.667834        0.586502  0.393945  0.521099   \n",
       "stdev     0.014642  0.013138         0.01389  0.012041  0.010104   \n",
       "n_trials        25        25               2        25        25   \n",
       "\n",
       "Metric                          r2                            \n",
       "Target   mean_columnwise   content   wording mean_columnwise  \n",
       "mean            0.457522  0.764228   0.58835        0.676289  \n",
       "stdev           0.011072  0.017718  0.019163        0.018441  \n",
       "n_trials               2        25        25               2  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "cross_validate(model,X_train,y_train,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv('feature_df.csv')\n",
    "merged_df_2 = pd.merge(merged_df, features_df, on=['student_id', 'prompt_id', 'text'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Columnwise Root Mean Squared Error (MCRMSE): 0.5574291357675863\n"
     ]
    }
   ],
   "source": [
    "selected_features = features_df.drop(columns=['student_id', 'prompt_id', 'text', 'content', 'wording'])\n",
    "\n",
    "selected_features_array = selected_features.values\n",
    "\n",
    "X_combined = np.hstack((X_embeddings, selected_features_array))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "model = MultiOutputRegressor(HistGradientBoostingRegressor(random_state=0))\n",
    "\n",
    "for train_i, test_i in k_folds.split(X_train):\n",
    "    fold_train_X, fold_test_X = X_train[train_i], X_train[test_i]\n",
    "    fold_train_y, fold_test_y = y_train.to_numpy()[train_i], y_train.to_numpy()[test_i]\n",
    "    model.fit(fold_train_X, fold_train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Columnwise Root Mean Squared Error (MCRMSE): 0.5046580605839339\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mcrmse_score = mcrmse(y_test, y_pred)\n",
    "print(\"Mean Columnwise Root Mean Squared Error (MCRMSE):\", mcrmse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 15:23:39,363 - INFO - Using 5x5 cross validation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90564cb8fc14d62946e2cf973863024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"3\" halign=\"left\">rmse</th>\n",
       "      <th colspan=\"3\" halign=\"left\">mae</th>\n",
       "      <th colspan=\"3\" halign=\"left\">r2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>mean_columnwise</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>mean_columnwise</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>mean_columnwise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.429815</td>\n",
       "      <td>0.57985</td>\n",
       "      <td>0.504833</td>\n",
       "      <td>0.325089</td>\n",
       "      <td>0.44464</td>\n",
       "      <td>0.384864</td>\n",
       "      <td>0.829466</td>\n",
       "      <td>0.689828</td>\n",
       "      <td>0.759647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stdev</th>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.015476</td>\n",
       "      <td>0.013477</td>\n",
       "      <td>0.007346</td>\n",
       "      <td>0.010607</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>0.010188</td>\n",
       "      <td>0.013033</td>\n",
       "      <td>0.011611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_trials</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric        rmse                                 mae            \\\n",
       "Target     content   wording mean_columnwise   content   wording   \n",
       "mean      0.429815   0.57985        0.504833  0.325089   0.44464   \n",
       "stdev     0.011478  0.015476        0.013477  0.007346  0.010607   \n",
       "n_trials        25        25               2        25        25   \n",
       "\n",
       "Metric                          r2                            \n",
       "Target   mean_columnwise   content   wording mean_columnwise  \n",
       "mean            0.384864  0.829466  0.689828        0.759647  \n",
       "stdev           0.008976  0.010188  0.013033        0.011611  \n",
       "n_trials               2        25        25               2  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "cross_validate(model, X_train, y_train, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "joe_features_df = pd.read_csv('joe_features.csv')\n",
    "\n",
    "selected_joe_features = joe_features_df[['mean word length', 'stopwords_count', 'repeated_words_prompt_text', 'repeated_words_prompt_question', 'fleschReadingEase']]\n",
    "\n",
    "selected_joe_features_array = selected_joe_features.values\n",
    "\n",
    "X_combined_with_joe_features = np.hstack((X_combined, selected_joe_features_array))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined_with_joe_features, y, test_size=0.2, random_state=42)\n",
    "model = MultiOutputRegressor(HistGradientBoostingRegressor(random_state=0))\n",
    "\n",
    "for train_i, test_i in k_folds.split(X_train):\n",
    "    fold_train_X, fold_test_X = X_train[train_i], X_train[test_i]\n",
    "    fold_train_y, fold_test_y = y_train.to_numpy()[train_i], y_train.to_numpy()[test_i]\n",
    "    model.fit(fold_train_X, fold_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 16:08:52,141 - INFO - Using 5x5 cross validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Columnwise Root Mean Squared Error (MCRMSE): 0.49645004388739866\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca6aa5e7c144c5abaa3a05a4318bb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"3\" halign=\"left\">rmse</th>\n",
       "      <th colspan=\"3\" halign=\"left\">mae</th>\n",
       "      <th colspan=\"3\" halign=\"left\">r2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Target</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>mean_columnwise</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>mean_columnwise</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>mean_columnwise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.428294</td>\n",
       "      <td>0.5756</td>\n",
       "      <td>0.501947</td>\n",
       "      <td>0.324224</td>\n",
       "      <td>0.440986</td>\n",
       "      <td>0.382605</td>\n",
       "      <td>0.830628</td>\n",
       "      <td>0.694359</td>\n",
       "      <td>0.762494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stdev</th>\n",
       "      <td>0.011868</td>\n",
       "      <td>0.015627</td>\n",
       "      <td>0.013747</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.010543</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>0.010949</td>\n",
       "      <td>0.013077</td>\n",
       "      <td>0.012013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_trials</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric        rmse                                 mae            \\\n",
       "Target     content   wording mean_columnwise   content   wording   \n",
       "mean      0.428294    0.5756        0.501947  0.324224  0.440986   \n",
       "stdev     0.011868  0.015627        0.013747  0.007379  0.010543   \n",
       "n_trials        25        25               2        25        25   \n",
       "\n",
       "Metric                          r2                            \n",
       "Target   mean_columnwise   content   wording mean_columnwise  \n",
       "mean            0.382605  0.830628  0.694359        0.762494  \n",
       "stdev           0.008961  0.010949  0.013077        0.012013  \n",
       "n_trials               2        25        25               2  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "mcrmse_score = mcrmse(y_test, y_pred)\n",
    "print(\"Mean Columnwise Root Mean Squared Error (MCRMSE):\", mcrmse_score)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "cross_validate(model, X_train, y_train, 5, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
