{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sys.path: ['c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\notebooks', 'C:\\\\Apps\\\\Anaconda3\\\\python311.zip', 'C:\\\\Apps\\\\Anaconda3\\\\DLLs', 'C:\\\\Apps\\\\Anaconda3\\\\Lib', 'C:\\\\Apps\\\\Anaconda3', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv', '', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:/Users/jp3g20/Desktop/summary_eval/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval']\n",
      "Updated sys.path: ['c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\notebooks', 'C:\\\\Apps\\\\Anaconda3\\\\python311.zip', 'C:\\\\Apps\\\\Anaconda3\\\\DLLs', 'C:\\\\Apps\\\\Anaconda3\\\\Lib', 'C:\\\\Apps\\\\Anaconda3', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv', '', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jp3g20\\\\Desktop\\\\data mining\\\\summary-eval\\\\venv\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:/Users/jp3g20/Desktop/summary_eval/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval', 'C:/Users/jp3g20/Desktop/data mining/summary-eval']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import string\n",
    "print('Original sys.path:', sys.path)\n",
    "\n",
    "# Append a new directory to sys.path\n",
    "sys.path.append('C:/Users/jp3g20/Desktop/data mining/summary-eval')\n",
    "\n",
    "# Print the updated sys.path\n",
    "print('Updated sys.path:', sys.path)\n",
    "from summary_eval.data import summary_df, prompts_df\n",
    "from summary_eval.settings import TRAIN_SIZE\n",
    "from summary_eval.testing import cross_validate\n",
    "\n",
    "merged_df = pd.merge(summary_df, prompts_df, on='prompt_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu118\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jp3g20\\Desktop\\data mining\\summary-eval\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Function to calculate average embedding of non-stopwords using BERT\n",
    "def calculate_average_bert_embedding(text):\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=True)\n",
    "\n",
    "    # Get BERT outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    \n",
    "    # Extract hidden states from BERT outputs\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "    \n",
    "    # Average pooling over all tokens (excluding padding tokens)\n",
    "    non_pad_mask = inputs[\"attention_mask\"].unsqueeze(-1).expand(hidden_states.size())\n",
    "    non_pad_hidden_states = hidden_states * non_pad_mask\n",
    "    sum_hidden_states = torch.sum(non_pad_hidden_states, 1)\n",
    "    sum_mask = non_pad_mask.sum(1)\n",
    "    mean_pooled = sum_hidden_states / sum_mask\n",
    "    \n",
    "    # Convert tensor to numpy array\n",
    "    avg_embedding = mean_pooled.squeeze().numpy()\n",
    "    \n",
    "    return avg_embedding\n",
    "\n",
    "# Apply function to 'text', 'prompt_text', and 'prompt_question' columns\n",
    "merged_df['text_embeddings'] = merged_df['text'].apply(calculate_average_bert_embedding)\n",
    "merged_df['prompt_embeddings'] = merged_df['prompt_text'].apply(calculate_average_bert_embedding)\n",
    "merged_df['prompt_question_embeddings'] = merged_df['prompt_question'].apply(calculate_average_bert_embedding)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('temp_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "n_folds = 10 \n",
    "\n",
    "k_folds = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "X_text_embeddings = np.vstack(merged_df['text_embeddings'].values)\n",
    "X_prompt_embeddings = np.vstack(merged_df['prompt_embeddings'].values)\n",
    "X_prompt_question_embeddings = np.vstack(merged_df['prompt_question_embeddings'].values)\n",
    "\n",
    "\n",
    "X_embeddings = np.hstack((X_text_embeddings, X_prompt_embeddings, X_prompt_question_embeddings))\n",
    "y = merged_df[['content', 'wording']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_embeddings, y, test_size=0.2, random_state=42)\n",
    "model = MultiOutputRegressor(HistGradientBoostingRegressor(random_state=0))\n",
    "\n",
    "for train_i, test_i in k_folds.split(X_train):\n",
    "    fold_train_X, fold_test_X = X_train[train_i], X_train[test_i]\n",
    "    fold_train_y, fold_test_y = y_train.to_numpy()[train_i], y_train.to_numpy()[test_i]\n",
    "    model.fit(fold_train_X, fold_train_y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.43415684788616127\n",
      "Mean Squared Error (MSE): 0.3164194877895337\n",
      "R-squared (R^2) score: 0.6991313738653087\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared (R^2) score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Columnwise Root Mean Squared Error (MCRMSE): 0.5574291357675863\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mcrmse(y_true, y_pred):\n",
    "    rmse_per_column = np.sqrt(np.mean((y_true - y_pred)**2, axis=0))\n",
    "    mcrmse_value = np.mean(rmse_per_column)\n",
    "    return mcrmse_value\n",
    "\n",
    "mcrmse_score = mcrmse(y_test, y_pred)\n",
    "print(\"Mean Columnwise Root Mean Squared Error (MCRMSE):\", mcrmse_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv('feature_df.csv')\n",
    "merged_df_2 = pd.merge(merged_df, features_df, on=['student_id', 'prompt_id', 'text'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
