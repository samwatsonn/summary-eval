{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sys.path: ['c:\\\\Users\\\\joepa\\\\OneDrive\\\\Desktop\\\\computerScienceYear4\\\\Data Mining\\\\summary_eval\\\\notebooks', 'C:\\\\Users\\\\joepa\\\\OneDrive\\\\Desktop\\\\computerScienceYear4\\\\Data Mining\\\\summary_eval', 'C:\\\\Users\\\\joepa\\\\anaconda3\\\\python39.zip', 'C:\\\\Users\\\\joepa\\\\anaconda3\\\\DLLs', 'C:\\\\Users\\\\joepa\\\\anaconda3\\\\lib', 'C:\\\\Users\\\\joepa\\\\anaconda3', 'c:\\\\Users\\\\joepa\\\\OneDrive\\\\Desktop\\\\computerScienceYear4\\\\Data Mining\\\\summary_eval\\\\venv', '', 'c:\\\\Users\\\\joepa\\\\OneDrive\\\\Desktop\\\\computerScienceYear4\\\\Data Mining\\\\summary_eval\\\\venv\\\\lib\\\\site-packages', 'c:\\\\Users\\\\joepa\\\\OneDrive\\\\Desktop\\\\computerScienceYear4\\\\Data Mining\\\\summary_eval\\\\venv\\\\lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\joepa\\\\OneDrive\\\\Desktop\\\\computerScienceYear4\\\\Data Mining\\\\summary_eval\\\\venv\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\joepa\\\\OneDrive\\\\Desktop\\\\computerScienceYear4\\\\Data Mining\\\\summary_eval\\\\venv\\\\lib\\\\site-packages\\\\Pythonwin']\n",
      "Updated sys.path: ['c:\\\\Users\\\\joepa\\\\OneDrive\\\\Desktop\\\\computerScienceYear4\\\\Data Mining\\\\summary_eval\\\\notebooks', 'C:\\\\Users\\\\joepa\\\\OneDrive\\\\Desktop\\\\computerScienceYear4\\\\Data Mining\\\\summary_eval', 'C:\\\\Users\\\\joepa\\\\anaconda3\\\\python39.zip', 'C:\\\\Users\\\\joepa\\\\anaconda3\\\\DLLs', 'C:\\\\Users\\\\joepa\\\\anaconda3\\\\lib', 'C:\\\\Users\\\\joepa\\\\anaconda3', 'c:\\\\Users\\\\joepa\\\\OneDrive\\\\Desktop\\\\computerScienceYear4\\\\Data Mining\\\\summary_eval\\\\venv', '', 'c:\\\\Users\\\\joepa\\\\OneDrive\\\\Desktop\\\\computerScienceYear4\\\\Data Mining\\\\summary_eval\\\\venv\\\\lib\\\\site-packages', 'c:\\\\Users\\\\joepa\\\\OneDrive\\\\Desktop\\\\computerScienceYear4\\\\Data Mining\\\\summary_eval\\\\venv\\\\lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\joepa\\\\OneDrive\\\\Desktop\\\\computerScienceYear4\\\\Data Mining\\\\summary_eval\\\\venv\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\joepa\\\\OneDrive\\\\Desktop\\\\computerScienceYear4\\\\Data Mining\\\\summary_eval\\\\venv\\\\lib\\\\site-packages\\\\Pythonwin', 'C:/Users/joepa/OneDrive/Desktop/computerScienceYear4/Data Mining/summary_eval/summary_eval']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 20:25:46,345 - INFO - Read 7165 summaries from C:\\Users\\joepa\\OneDrive\\Desktop\\computerScienceYear4\\Data Mining\\summary_eval\\data\\summaries_train.csv\n",
      "2024-03-16 20:25:46,365 - INFO - Read 4 prompts from C:\\Users\\joepa\\OneDrive\\Desktop\\computerScienceYear4\\Data Mining\\summary_eval\\data\\prompts_train.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import string\n",
    "print('Original sys.path:', sys.path)\n",
    "\n",
    "# Append a new directory to sys.path\n",
    "sys.path.append('C:/Users/joepa/OneDrive/Desktop/computerScienceYear4/Data Mining/summary_eval/summary_eval')\n",
    "\n",
    "# Print the updated sys.path\n",
    "print('Updated sys.path:', sys.path)\n",
    "from summary_eval.data import summary_df, prompts_df\n",
    "from summary_eval.settings import TRAIN_SIZE\n",
    "from summary_eval.testing import cross_validate\n",
    "\n",
    "merged_df = pd.merge(summary_df, prompts_df, on='prompt_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertModel\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Generate BERT embeddings\n",
    "def generate_bert_embeddings(text):\n",
    "    with torch.no_grad():\n",
    "        tokens = tokenizer.encode(text, add_special_tokens=True)\n",
    "        outputs = bert_model(torch.tensor([tokens]))\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()  # Average pooling over all tokens\n",
    "\n",
    "# Apply function to 'text', 'prompt_text', and 'prompt_question' columns\n",
    "merged_df['text_embeddings'] = merged_df['text'].apply(generate_bert_embeddings)\n",
    "merged_df['prompt_embeddings'] = merged_df['prompt_text'].apply(generate_bert_embeddings)\n",
    "merged_df['prompt_question_embeddings'] = merged_df['prompt_question'].apply(generate_bert_embeddings)\n",
    "\n",
    "# Concatenate embeddings\n",
    "X = np.concatenate([\n",
    "    np.stack(merged_df['text_embeddings'].values),\n",
    "    np.stack(merged_df['prompt_embeddings'].values),\n",
    "    np.stack(merged_df['prompt_question_embeddings'].values)\n",
    "], axis=1)\n",
    "\n",
    "# Define targets\n",
    "y = merged_df[['content_score', 'wording_score']]\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose model\n",
    "model = LinearRegression()\n",
    "# model = RandomForestRegressor()\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
